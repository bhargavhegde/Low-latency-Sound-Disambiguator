# ğŸ§ Low-Latency Sound Disambiguator

<div align="center">

> Real-Time Audio Intelligence Dashboard for Sound Awareness

[![Hackathon Track](https://img.shields.io/badge/Track-AI%20for%20Accessibility-blue)](https://github.com/rohitsagar363/Low-latency-Sound-Disambiguator)
[![Edge Intelligence](https://img.shields.io/badge/Technology-Edge%20Intelligence-green)](https://github.com/rohitsagar363/Low-latency-Sound-Disambiguator)

</div>

## ğŸ¯ Mission

Empowering deaf and hearing-impaired individuals with real-time sound awareness through AI-powered visual alerts.

## ğŸ§© Overview

The **Low-Latency Sound Disambiguator** transforms environmental sounds into instant visual alerts, making the auditory world accessible to everyone. Our system:

- ğŸ¤ **Captures** continuous audio input in real-time
- ğŸ¤– **Analyzes** sounds using Google's YAMNet ML model
- ğŸ§  **Interprets** context through Ollama (Mistral) AI
- ğŸ“Š **Visualizes** alerts through an intuitive dashboard

## ğŸš¨ Use Case Example: Police Siren Detection

<div align="center">

### Without Sound Disambiguator
<img src="/images/before_siren.png" alt="Without System" width="600"/>

*A deaf person unable to hear approaching emergency vehicle sirens*

### With Sound Disambiguator
<img src="/images/with_siren.png" alt="With System" width="600"/>

*Real-time visual alert showing:*
- ğŸš“ **Detection**: Police siren detected
- ğŸ“ **Direction**: Coming from behind, ~100m away
- ğŸ”Š **Intensity**: High (Emergency vehicle approaching)
- âš ï¸ **Action Required**: Move to the side of the road

</div>

## ğŸ“Š Dashboard Interface

### ğŸ¯ Live Tab
<img src="/images/live_tab.png" alt="Live Dashboard" width="800"/>

*Real-time monitoring and detection interface*
- Sound classification with confidence levels
- Direction indicator with spatial awareness
- Color-coded alert banner system
- Live AI interpretations of detected sounds

### ğŸ“œ History Tab
<img src="/images/history_tab.png" alt="History View" width="800"/>

*Historical data and event tracking*
- Chronological log of detected sounds
- Time-stamped events with classifications
- Filter and search functionality
- Export capabilities for analysis

### ğŸ“ˆ Analytics Tab
<img src="/images/analytics_tab.png" alt="Analytics Dashboard" width="800"/>

*Statistical analysis and insights*
- Sound type distribution charts
- Temporal pattern analysis
- Alert frequency statistics
- Performance metrics visualization

### ğŸ§  Insights Tab
<img src="/images/insights_tab.png" alt="AI Insights" width="800"/>

*AI-powered interpretation and recommendations*
- Contextual sound interpretations
- Pattern recognition summaries
- Environmental safety scoring
- Actionable safety recommendations

## ğŸ—ï¸ System Architecture

```mermaid
graph TD
    A[ğŸ¤ Microphone Input] --> B[SoundDevice Stream]
    B --> C[YAMNet Model]
    C --> D{Sound Classification}
    D -->|Confidence & Label| E[Live Dashboard]
    D -->|Events| H[Analytics Engine]
    E --> F[Ollama Mistral]
    F --> G[Insights Generation]
    H --> I[Historical Data]
    E --> J[Alert System]
    J -->|Status| K[Visual Indicators]
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#bbf,stroke:#333,stroke-width:2px
    style J fill:#fbb,stroke:#333,stroke-width:2px
```

## ğŸ§° Technology Stack

| Layer | Components | Description |
|-------|------------|-------------|
| ğŸ¨ Frontend | Streamlit, Plotly | Interactive dashboard with real-time updates |
| ğŸµ Audio | SoundDevice, NumPy | High-performance audio stream processing |
| ğŸ¤– ML/AI | TensorFlow Hub, YAMNet | Sound classification and analysis |
| ğŸ§  Intelligence | Ollama (Mistral) | Local LLM for context interpretation |
| ğŸ”„ Processing | Threading, Queue | Concurrent operation handling |
| ğŸ“Š Visualization | Plotly, Custom CSS | Dynamic charts and alert banners |
